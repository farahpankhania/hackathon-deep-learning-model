{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sivn_PH62Bs7",
        "outputId": "45ebc212-67cd-4f2d-96bd-940d41062ad0"
      },
      "id": "Sivn_PH62Bs7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# %cd '/content/drive/MyDrive/Criteo_data'\n",
        "%cd '/content/drive/Shareddrives/Criteo Workspace'\n",
        "# df_golden = pd.read_parquet('golden.parquet')\n",
        "\n",
        "df_golden = pd.read_feather('golden_fulldata.feather')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvu1DkAy2Cjw",
        "outputId": "a54b7c01-c636-4314-8763-202c4193b98f"
      },
      "id": "uvu1DkAy2Cjw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/Criteo Workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "02f16115",
      "metadata": {
        "id": "02f16115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "c8922b63-c23e-44d9-ddc5-88a48890cfa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0   0.189755   0.215585   0.219336  -0.593121   0.097516  -0.234115   \n",
              "1  -0.175385   0.211454   0.163345  -0.554972  -0.184808  -0.045058   \n",
              "2  -0.353085   0.349696   0.167092  -0.467489  -0.114193  -0.188712   \n",
              "3   0.111453   0.339091   0.242156  -0.509561  -0.248914  -0.275583   \n",
              "4  -0.317834  -0.123965   0.216823  -0.715437   0.275252   0.461574   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_191  feature_192  \\\n",
              "0   0.249395   0.405693   0.511828   0.169659  ...    -0.070646    -0.742424   \n",
              "1   0.047618   0.056900   0.618071   0.197163  ...     0.100182    -0.836602   \n",
              "2   0.318389   0.143173   0.770127   0.304752  ...    -0.032867    -1.339714   \n",
              "3   0.055723  -0.084819   0.679301  -0.183641  ...     0.262598    -0.485186   \n",
              "4   0.059469   0.343792   0.630168   0.086415  ...    -0.116973    -0.772714   \n",
              "\n",
              "   feature_193  feature_194  feature_195  feature_196  feature_197  \\\n",
              "0     0.083330    -0.060717     0.492582    -0.205874    -0.150932   \n",
              "1     0.149833    -0.144223     0.252820     0.127420    -0.364270   \n",
              "2     0.512739    -0.326310     0.515937     0.027558    -0.478302   \n",
              "3     0.277914     0.098953    -0.102034    -0.316155    -0.037034   \n",
              "4     0.473733    -0.077875     0.829760     0.062484    -0.239351   \n",
              "\n",
              "   feature_198  feature_199  target  \n",
              "0     0.131489    -0.465388     540  \n",
              "1     0.268537    -0.194119     541  \n",
              "2     0.323910    -0.331167     532  \n",
              "3    -0.128927    -0.701687     508  \n",
              "4     0.120232    -0.194506    1975  \n",
              "\n",
              "[5 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a40bd6d7-1e3c-4e7a-805b-d7af08712553\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_191</th>\n",
              "      <th>feature_192</th>\n",
              "      <th>feature_193</th>\n",
              "      <th>feature_194</th>\n",
              "      <th>feature_195</th>\n",
              "      <th>feature_196</th>\n",
              "      <th>feature_197</th>\n",
              "      <th>feature_198</th>\n",
              "      <th>feature_199</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.189755</td>\n",
              "      <td>0.215585</td>\n",
              "      <td>0.219336</td>\n",
              "      <td>-0.593121</td>\n",
              "      <td>0.097516</td>\n",
              "      <td>-0.234115</td>\n",
              "      <td>0.249395</td>\n",
              "      <td>0.405693</td>\n",
              "      <td>0.511828</td>\n",
              "      <td>0.169659</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070646</td>\n",
              "      <td>-0.742424</td>\n",
              "      <td>0.083330</td>\n",
              "      <td>-0.060717</td>\n",
              "      <td>0.492582</td>\n",
              "      <td>-0.205874</td>\n",
              "      <td>-0.150932</td>\n",
              "      <td>0.131489</td>\n",
              "      <td>-0.465388</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.175385</td>\n",
              "      <td>0.211454</td>\n",
              "      <td>0.163345</td>\n",
              "      <td>-0.554972</td>\n",
              "      <td>-0.184808</td>\n",
              "      <td>-0.045058</td>\n",
              "      <td>0.047618</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>0.618071</td>\n",
              "      <td>0.197163</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100182</td>\n",
              "      <td>-0.836602</td>\n",
              "      <td>0.149833</td>\n",
              "      <td>-0.144223</td>\n",
              "      <td>0.252820</td>\n",
              "      <td>0.127420</td>\n",
              "      <td>-0.364270</td>\n",
              "      <td>0.268537</td>\n",
              "      <td>-0.194119</td>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.353085</td>\n",
              "      <td>0.349696</td>\n",
              "      <td>0.167092</td>\n",
              "      <td>-0.467489</td>\n",
              "      <td>-0.114193</td>\n",
              "      <td>-0.188712</td>\n",
              "      <td>0.318389</td>\n",
              "      <td>0.143173</td>\n",
              "      <td>0.770127</td>\n",
              "      <td>0.304752</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032867</td>\n",
              "      <td>-1.339714</td>\n",
              "      <td>0.512739</td>\n",
              "      <td>-0.326310</td>\n",
              "      <td>0.515937</td>\n",
              "      <td>0.027558</td>\n",
              "      <td>-0.478302</td>\n",
              "      <td>0.323910</td>\n",
              "      <td>-0.331167</td>\n",
              "      <td>532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.111453</td>\n",
              "      <td>0.339091</td>\n",
              "      <td>0.242156</td>\n",
              "      <td>-0.509561</td>\n",
              "      <td>-0.248914</td>\n",
              "      <td>-0.275583</td>\n",
              "      <td>0.055723</td>\n",
              "      <td>-0.084819</td>\n",
              "      <td>0.679301</td>\n",
              "      <td>-0.183641</td>\n",
              "      <td>...</td>\n",
              "      <td>0.262598</td>\n",
              "      <td>-0.485186</td>\n",
              "      <td>0.277914</td>\n",
              "      <td>0.098953</td>\n",
              "      <td>-0.102034</td>\n",
              "      <td>-0.316155</td>\n",
              "      <td>-0.037034</td>\n",
              "      <td>-0.128927</td>\n",
              "      <td>-0.701687</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.317834</td>\n",
              "      <td>-0.123965</td>\n",
              "      <td>0.216823</td>\n",
              "      <td>-0.715437</td>\n",
              "      <td>0.275252</td>\n",
              "      <td>0.461574</td>\n",
              "      <td>0.059469</td>\n",
              "      <td>0.343792</td>\n",
              "      <td>0.630168</td>\n",
              "      <td>0.086415</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.116973</td>\n",
              "      <td>-0.772714</td>\n",
              "      <td>0.473733</td>\n",
              "      <td>-0.077875</td>\n",
              "      <td>0.829760</td>\n",
              "      <td>0.062484</td>\n",
              "      <td>-0.239351</td>\n",
              "      <td>0.120232</td>\n",
              "      <td>-0.194506</td>\n",
              "      <td>1975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a40bd6d7-1e3c-4e7a-805b-d7af08712553')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a40bd6d7-1e3c-4e7a-805b-d7af08712553 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a40bd6d7-1e3c-4e7a-805b-d7af08712553');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Read the golden feather file\n",
        "df_golden.set_axis([f'feature_{i}' for i in range(200)] + ['target'], axis=1, inplace=True)\n",
        "\n",
        "df_golden['target'] = df_golden['target'].astype(int)\n",
        "\n",
        "df_golden['target'] = df_golden['target'].astype('category')\n",
        "# Show the first few rows of the dataframe\n",
        "df_golden.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_golden['target'] = df_golden['target'].astype('category')\n",
        "# Show the first few rows of the dataframe\n",
        "df_golden.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "eLrq__FY10s1",
        "outputId": "451658af-5f0e-4566-e999-d8009d6294fa"
      },
      "id": "eLrq__FY10s1",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0   0.189755   0.215585   0.219336  -0.593121   0.097516  -0.234115   \n",
              "1  -0.175385   0.211454   0.163345  -0.554972  -0.184808  -0.045058   \n",
              "2  -0.353085   0.349696   0.167092  -0.467489  -0.114193  -0.188712   \n",
              "3   0.111453   0.339091   0.242156  -0.509561  -0.248914  -0.275583   \n",
              "4  -0.317834  -0.123965   0.216823  -0.715437   0.275252   0.461574   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_191  feature_192  \\\n",
              "0   0.249395   0.405693   0.511828   0.169659  ...    -0.070646    -0.742424   \n",
              "1   0.047618   0.056900   0.618071   0.197163  ...     0.100182    -0.836602   \n",
              "2   0.318389   0.143173   0.770127   0.304752  ...    -0.032867    -1.339714   \n",
              "3   0.055723  -0.084819   0.679301  -0.183641  ...     0.262598    -0.485186   \n",
              "4   0.059469   0.343792   0.630168   0.086415  ...    -0.116973    -0.772714   \n",
              "\n",
              "   feature_193  feature_194  feature_195  feature_196  feature_197  \\\n",
              "0     0.083330    -0.060717     0.492582    -0.205874    -0.150932   \n",
              "1     0.149833    -0.144223     0.252820     0.127420    -0.364270   \n",
              "2     0.512739    -0.326310     0.515937     0.027558    -0.478302   \n",
              "3     0.277914     0.098953    -0.102034    -0.316155    -0.037034   \n",
              "4     0.473733    -0.077875     0.829760     0.062484    -0.239351   \n",
              "\n",
              "   feature_198  feature_199  target  \n",
              "0     0.131489    -0.465388     540  \n",
              "1     0.268537    -0.194119     541  \n",
              "2     0.323910    -0.331167     532  \n",
              "3    -0.128927    -0.701687     508  \n",
              "4     0.120232    -0.194506    1975  \n",
              "\n",
              "[5 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8b54644-c829-49bc-8007-f5adac05da6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_191</th>\n",
              "      <th>feature_192</th>\n",
              "      <th>feature_193</th>\n",
              "      <th>feature_194</th>\n",
              "      <th>feature_195</th>\n",
              "      <th>feature_196</th>\n",
              "      <th>feature_197</th>\n",
              "      <th>feature_198</th>\n",
              "      <th>feature_199</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.189755</td>\n",
              "      <td>0.215585</td>\n",
              "      <td>0.219336</td>\n",
              "      <td>-0.593121</td>\n",
              "      <td>0.097516</td>\n",
              "      <td>-0.234115</td>\n",
              "      <td>0.249395</td>\n",
              "      <td>0.405693</td>\n",
              "      <td>0.511828</td>\n",
              "      <td>0.169659</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070646</td>\n",
              "      <td>-0.742424</td>\n",
              "      <td>0.083330</td>\n",
              "      <td>-0.060717</td>\n",
              "      <td>0.492582</td>\n",
              "      <td>-0.205874</td>\n",
              "      <td>-0.150932</td>\n",
              "      <td>0.131489</td>\n",
              "      <td>-0.465388</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.175385</td>\n",
              "      <td>0.211454</td>\n",
              "      <td>0.163345</td>\n",
              "      <td>-0.554972</td>\n",
              "      <td>-0.184808</td>\n",
              "      <td>-0.045058</td>\n",
              "      <td>0.047618</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>0.618071</td>\n",
              "      <td>0.197163</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100182</td>\n",
              "      <td>-0.836602</td>\n",
              "      <td>0.149833</td>\n",
              "      <td>-0.144223</td>\n",
              "      <td>0.252820</td>\n",
              "      <td>0.127420</td>\n",
              "      <td>-0.364270</td>\n",
              "      <td>0.268537</td>\n",
              "      <td>-0.194119</td>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.353085</td>\n",
              "      <td>0.349696</td>\n",
              "      <td>0.167092</td>\n",
              "      <td>-0.467489</td>\n",
              "      <td>-0.114193</td>\n",
              "      <td>-0.188712</td>\n",
              "      <td>0.318389</td>\n",
              "      <td>0.143173</td>\n",
              "      <td>0.770127</td>\n",
              "      <td>0.304752</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032867</td>\n",
              "      <td>-1.339714</td>\n",
              "      <td>0.512739</td>\n",
              "      <td>-0.326310</td>\n",
              "      <td>0.515937</td>\n",
              "      <td>0.027558</td>\n",
              "      <td>-0.478302</td>\n",
              "      <td>0.323910</td>\n",
              "      <td>-0.331167</td>\n",
              "      <td>532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.111453</td>\n",
              "      <td>0.339091</td>\n",
              "      <td>0.242156</td>\n",
              "      <td>-0.509561</td>\n",
              "      <td>-0.248914</td>\n",
              "      <td>-0.275583</td>\n",
              "      <td>0.055723</td>\n",
              "      <td>-0.084819</td>\n",
              "      <td>0.679301</td>\n",
              "      <td>-0.183641</td>\n",
              "      <td>...</td>\n",
              "      <td>0.262598</td>\n",
              "      <td>-0.485186</td>\n",
              "      <td>0.277914</td>\n",
              "      <td>0.098953</td>\n",
              "      <td>-0.102034</td>\n",
              "      <td>-0.316155</td>\n",
              "      <td>-0.037034</td>\n",
              "      <td>-0.128927</td>\n",
              "      <td>-0.701687</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.317834</td>\n",
              "      <td>-0.123965</td>\n",
              "      <td>0.216823</td>\n",
              "      <td>-0.715437</td>\n",
              "      <td>0.275252</td>\n",
              "      <td>0.461574</td>\n",
              "      <td>0.059469</td>\n",
              "      <td>0.343792</td>\n",
              "      <td>0.630168</td>\n",
              "      <td>0.086415</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.116973</td>\n",
              "      <td>-0.772714</td>\n",
              "      <td>0.473733</td>\n",
              "      <td>-0.077875</td>\n",
              "      <td>0.829760</td>\n",
              "      <td>0.062484</td>\n",
              "      <td>-0.239351</td>\n",
              "      <td>0.120232</td>\n",
              "      <td>-0.194506</td>\n",
              "      <td>1975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8b54644-c829-49bc-8007-f5adac05da6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8b54644-c829-49bc-8007-f5adac05da6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8b54644-c829-49bc-8007-f5adac05da6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b5f9c142",
      "metadata": {
        "id": "b5f9c142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "375c0269-197f-4c41-875f-515f2fdc59dd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9714/9714 [==============================] - 48s 4ms/step - loss: 2.2658 - accuracy: 0.6167 - val_loss: 1.5136 - val_accuracy: 0.7235\n",
            "Epoch 2/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 1.1885 - accuracy: 0.7509 - val_loss: 1.2882 - val_accuracy: 0.7566\n",
            "Epoch 3/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 0.9527 - accuracy: 0.7792 - val_loss: 1.2228 - val_accuracy: 0.7658\n",
            "Epoch 4/50\n",
            "9714/9714 [==============================] - 41s 4ms/step - loss: 0.8353 - accuracy: 0.7948 - val_loss: 1.2211 - val_accuracy: 0.7732\n",
            "Epoch 5/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 0.7636 - accuracy: 0.8060 - val_loss: 1.1935 - val_accuracy: 0.7755\n",
            "Epoch 6/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 0.7143 - accuracy: 0.8147 - val_loss: 1.2066 - val_accuracy: 0.7744\n",
            "Epoch 7/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 0.6772 - accuracy: 0.8195 - val_loss: 1.2319 - val_accuracy: 0.7761\n",
            "Epoch 8/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 0.6500 - accuracy: 0.8257 - val_loss: 1.2581 - val_accuracy: 0.7757\n",
            "Epoch 9/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 0.6278 - accuracy: 0.8313 - val_loss: 1.2675 - val_accuracy: 0.7760\n",
            "Epoch 10/50\n",
            "9714/9714 [==============================] - 42s 4ms/step - loss: 0.6112 - accuracy: 0.8356 - val_loss: 1.3050 - val_accuracy: 0.7739\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1301/1301 [==============================] - 2s 1ms/step\n",
            "Actual values: [343 338 290 ... 375 366 338]\n",
            "Predicted values: [343 338 288 ... 375 366 338]\n",
            "Accuracy: 0.78\n",
            "Precision: 0.76\n",
            "Recall: 0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#base model on golden\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# read data and apply one-hot encoding\n",
        "data = df_golden\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1:]\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(y)\n",
        "y = ohe.transform(y)\n",
        "\n",
        "n_input = X.shape[-1]\n",
        "n_class = y.shape[-1]\n",
        "n_hidden = 50\n",
        "\n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "\n",
        "# build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(n_hidden, input_shape=(n_input,), activation='relu'),\n",
        "    tf.keras.layers.Dense(n_class, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# define early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# train the model with early stopping\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# plot the loss and accuracy\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('cross entropy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# save the model\n",
        "model.save('base_model')\n",
        "\n",
        "# Save the golden test set to a file\n",
        "np.savez('gold_test_set.npz', X_test=X_test, y_test=y_test)\n",
        "\n",
        "# make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# convert the predicted probabilities to class labels\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "# compare actual and predicted values\n",
        "print(\"Actual values:\", y_test)\n",
        "print(\"Predicted values:\", y_pred)\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "error_rate = 1 - accuracy\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "# create a DataFrame with predicted and actual labels\n",
        "pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "\n",
        "# filter for rows where predicted and actual labels are different\n",
        "misclassified = pred_df[pred_df['Actual'] != pred_df['Predicted']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#performing prediction on df_golden_unlabelled provided by criteo using the above base model\n",
        "\n",
        "#loading the unlabelled golden test feather file\n",
        "df_golden_unlabelled = pd.read_feather('golden_dataset_without_labels.feather')\n",
        "df_golden_unlabelled.head()\n",
        "\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the base model\n",
        "# base_model = load_model('base_model')\n",
        "\n",
        "# Make predictions on the unlabelled data\n",
        "predictions = model.predict(df_golden_unlabelled.iloc[:,:-1])\n",
        "\n",
        "# Add the predicted values as a new column in the dataframe\n",
        "df_golden_unlabelled['target'] = predictions.argmax(axis=-1)\n",
        "\n",
        "df_golden_unlabelled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "9i_iQq8KjzJi",
        "outputId": "f7cfdfe9-3aa7-4fbe-ba21-5f474ec31f43"
      },
      "id": "9i_iQq8KjzJi",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15484/15484 [==============================] - 20s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0   0.101940  -0.017286   0.084953  -0.951696   0.352282  -0.346768   \n",
              "1   0.231260   0.334692   0.026797  -0.631820   0.270041  -0.149977   \n",
              "2   0.270674   0.118883   0.189267  -0.579700   0.104969   0.061038   \n",
              "3   0.868857   0.153640   0.044309  -0.928379   0.395467  -0.524435   \n",
              "4   0.624732   0.079210   0.098733  -0.876559   0.456947  -0.599581   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_191  feature_192  \\\n",
              "0   0.138993   0.086502   0.714200  -0.146041  ...    -0.447730    -0.532086   \n",
              "1   0.063132   0.375346   0.292597   0.204015  ...    -0.374579    -0.789437   \n",
              "2   0.017830   0.210072   0.375069   0.097011  ...    -0.277504    -0.807677   \n",
              "3   0.404115   0.475237   0.501009  -0.077508  ...    -0.520704    -0.622285   \n",
              "4   0.490737  -0.052870   0.939491   0.025928  ...    -0.453360    -0.640561   \n",
              "\n",
              "   feature_193  feature_194  feature_195  feature_196  feature_197  \\\n",
              "0    -0.224644    -0.228299     0.090918     0.183534    -0.132292   \n",
              "1    -0.012622    -0.099412    -0.150186    -0.102274    -0.073857   \n",
              "2     0.120687    -0.258360    -0.112257    -0.071628    -0.092532   \n",
              "3    -0.547424    -0.231111     0.151586     0.130592     0.081846   \n",
              "4    -0.455199    -0.552339    -0.157240     0.103550    -0.402685   \n",
              "\n",
              "   feature_198  feature_199  target  \n",
              "0    -0.090970    -0.503340     375  \n",
              "1     0.199650    -0.118662     366  \n",
              "2     0.173010    -0.166538     366  \n",
              "3     0.153175    -0.599044     374  \n",
              "4     0.146011    -0.118169     392  \n",
              "\n",
              "[5 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3a149e2-9be5-4610-9bdc-aa1cb2f43ff9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_191</th>\n",
              "      <th>feature_192</th>\n",
              "      <th>feature_193</th>\n",
              "      <th>feature_194</th>\n",
              "      <th>feature_195</th>\n",
              "      <th>feature_196</th>\n",
              "      <th>feature_197</th>\n",
              "      <th>feature_198</th>\n",
              "      <th>feature_199</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.101940</td>\n",
              "      <td>-0.017286</td>\n",
              "      <td>0.084953</td>\n",
              "      <td>-0.951696</td>\n",
              "      <td>0.352282</td>\n",
              "      <td>-0.346768</td>\n",
              "      <td>0.138993</td>\n",
              "      <td>0.086502</td>\n",
              "      <td>0.714200</td>\n",
              "      <td>-0.146041</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.447730</td>\n",
              "      <td>-0.532086</td>\n",
              "      <td>-0.224644</td>\n",
              "      <td>-0.228299</td>\n",
              "      <td>0.090918</td>\n",
              "      <td>0.183534</td>\n",
              "      <td>-0.132292</td>\n",
              "      <td>-0.090970</td>\n",
              "      <td>-0.503340</td>\n",
              "      <td>375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.231260</td>\n",
              "      <td>0.334692</td>\n",
              "      <td>0.026797</td>\n",
              "      <td>-0.631820</td>\n",
              "      <td>0.270041</td>\n",
              "      <td>-0.149977</td>\n",
              "      <td>0.063132</td>\n",
              "      <td>0.375346</td>\n",
              "      <td>0.292597</td>\n",
              "      <td>0.204015</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>-0.789437</td>\n",
              "      <td>-0.012622</td>\n",
              "      <td>-0.099412</td>\n",
              "      <td>-0.150186</td>\n",
              "      <td>-0.102274</td>\n",
              "      <td>-0.073857</td>\n",
              "      <td>0.199650</td>\n",
              "      <td>-0.118662</td>\n",
              "      <td>366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.270674</td>\n",
              "      <td>0.118883</td>\n",
              "      <td>0.189267</td>\n",
              "      <td>-0.579700</td>\n",
              "      <td>0.104969</td>\n",
              "      <td>0.061038</td>\n",
              "      <td>0.017830</td>\n",
              "      <td>0.210072</td>\n",
              "      <td>0.375069</td>\n",
              "      <td>0.097011</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.277504</td>\n",
              "      <td>-0.807677</td>\n",
              "      <td>0.120687</td>\n",
              "      <td>-0.258360</td>\n",
              "      <td>-0.112257</td>\n",
              "      <td>-0.071628</td>\n",
              "      <td>-0.092532</td>\n",
              "      <td>0.173010</td>\n",
              "      <td>-0.166538</td>\n",
              "      <td>366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.868857</td>\n",
              "      <td>0.153640</td>\n",
              "      <td>0.044309</td>\n",
              "      <td>-0.928379</td>\n",
              "      <td>0.395467</td>\n",
              "      <td>-0.524435</td>\n",
              "      <td>0.404115</td>\n",
              "      <td>0.475237</td>\n",
              "      <td>0.501009</td>\n",
              "      <td>-0.077508</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.520704</td>\n",
              "      <td>-0.622285</td>\n",
              "      <td>-0.547424</td>\n",
              "      <td>-0.231111</td>\n",
              "      <td>0.151586</td>\n",
              "      <td>0.130592</td>\n",
              "      <td>0.081846</td>\n",
              "      <td>0.153175</td>\n",
              "      <td>-0.599044</td>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.624732</td>\n",
              "      <td>0.079210</td>\n",
              "      <td>0.098733</td>\n",
              "      <td>-0.876559</td>\n",
              "      <td>0.456947</td>\n",
              "      <td>-0.599581</td>\n",
              "      <td>0.490737</td>\n",
              "      <td>-0.052870</td>\n",
              "      <td>0.939491</td>\n",
              "      <td>0.025928</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.453360</td>\n",
              "      <td>-0.640561</td>\n",
              "      <td>-0.455199</td>\n",
              "      <td>-0.552339</td>\n",
              "      <td>-0.157240</td>\n",
              "      <td>0.103550</td>\n",
              "      <td>-0.402685</td>\n",
              "      <td>0.146011</td>\n",
              "      <td>-0.118169</td>\n",
              "      <td>392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3a149e2-9be5-4610-9bdc-aa1cb2f43ff9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3a149e2-9be5-4610-9bdc-aa1cb2f43ff9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3a149e2-9be5-4610-9bdc-aa1cb2f43ff9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataframe to a numpy array\n",
        "import numpy as np\n",
        "data = df_golden_unlabelled.values\n",
        "\n",
        "# Save the numpy array as a .npy file\n",
        "np.save('Group13_Prediction_1.npy', data)"
      ],
      "metadata": {
        "id": "_J5x-CiVkZkd"
      },
      "id": "_J5x-CiVkZkd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e533d4",
      "metadata": {
        "id": "53e533d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca0b2cb-2db0-48ac-94b5-a514dcd06f8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2624599, 201)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Load the bulk feather file\n",
        "df_bulk = pd.read_feather('bulk_fulldata.feather')\n",
        "\n",
        "# Show the first few rows of the dataframe\n",
        "df_bulk.head()\n",
        "\n",
        "df_bulk.set_axis([f'feature_{i}' for i in range(200)] + ['target'], axis=1, inplace=True)\n",
        "df_bulk.head()\n",
        "\n",
        "df_bulk['target'] = df_bulk['target'].astype(int)\n",
        "df_bulk.head()\n",
        "\n",
        "df_bulk['target'] = df_bulk['target'].astype('category')\n",
        "df_bulk.dtypes\n",
        "\n",
        "# get the list of misclassified class labels\n",
        "misclassified_labels = misclassified['Actual'].unique()\n",
        "\n",
        "# filter df_bulk based on misclassified_labels\n",
        "df_bulk_subset = df_bulk[df_bulk['target'].isin(misclassified_labels)]\n",
        "\n",
        "df_bulk_subset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79c7348a",
      "metadata": {
        "id": "79c7348a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6203a533-d75d-415c-cc5a-a5fe2365adc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/3\n",
            "Epoch 1/8\n",
            "12794/12794 [==============================] - 57s 4ms/step - loss: 2.1412 - accuracy: 0.6394 - val_loss: 1.4992 - val_accuracy: 0.7294\n",
            "Epoch 2/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 1.1640 - accuracy: 0.7614 - val_loss: 1.2843 - val_accuracy: 0.7615\n",
            "Epoch 3/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.9516 - accuracy: 0.7859 - val_loss: 1.2232 - val_accuracy: 0.7700\n",
            "Epoch 4/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.8432 - accuracy: 0.7990 - val_loss: 1.2000 - val_accuracy: 0.7740\n",
            "Epoch 5/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.7784 - accuracy: 0.8089 - val_loss: 1.2200 - val_accuracy: 0.7741\n",
            "Epoch 6/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.7315 - accuracy: 0.8145 - val_loss: 1.2289 - val_accuracy: 0.7790\n",
            "Epoch 7/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.6951 - accuracy: 0.8209 - val_loss: 1.2440 - val_accuracy: 0.7738\n",
            "Epoch 8/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.6685 - accuracy: 0.8257 - val_loss: 1.2487 - val_accuracy: 0.7776\n",
            "Validation accuracy: 0.7775903344154358\n",
            "Iteration 2/3\n",
            "Epoch 1/8\n",
            "12794/12794 [==============================] - 56s 4ms/step - loss: 2.1649 - accuracy: 0.6380 - val_loss: 1.4759 - val_accuracy: 0.7337\n",
            "Epoch 2/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 1.1848 - accuracy: 0.7583 - val_loss: 1.2737 - val_accuracy: 0.7647\n",
            "Epoch 3/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.9681 - accuracy: 0.7840 - val_loss: 1.1977 - val_accuracy: 0.7727\n",
            "Epoch 4/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.8568 - accuracy: 0.7983 - val_loss: 1.1832 - val_accuracy: 0.7752\n",
            "Epoch 5/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.7924 - accuracy: 0.8059 - val_loss: 1.1894 - val_accuracy: 0.7770\n",
            "Epoch 6/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.7428 - accuracy: 0.8154 - val_loss: 1.2350 - val_accuracy: 0.7770\n",
            "Epoch 7/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.7065 - accuracy: 0.8204 - val_loss: 1.2406 - val_accuracy: 0.7824\n",
            "Epoch 8/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.6793 - accuracy: 0.8238 - val_loss: 1.2177 - val_accuracy: 0.7784\n",
            "Validation accuracy: 0.778365433216095\n",
            "Iteration 3/3\n",
            "Epoch 1/8\n",
            "12794/12794 [==============================] - 57s 4ms/step - loss: 2.1757 - accuracy: 0.6385 - val_loss: 1.5300 - val_accuracy: 0.7267\n",
            "Epoch 2/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 1.2019 - accuracy: 0.7576 - val_loss: 1.2972 - val_accuracy: 0.7586\n",
            "Epoch 3/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.9796 - accuracy: 0.7838 - val_loss: 1.2522 - val_accuracy: 0.7680\n",
            "Epoch 4/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.8693 - accuracy: 0.7967 - val_loss: 1.2368 - val_accuracy: 0.7708\n",
            "Epoch 5/8\n",
            "12794/12794 [==============================] - 56s 4ms/step - loss: 0.7987 - accuracy: 0.8066 - val_loss: 1.2206 - val_accuracy: 0.7726\n",
            "Epoch 6/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.7516 - accuracy: 0.8123 - val_loss: 1.2104 - val_accuracy: 0.7742\n",
            "Epoch 7/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.7146 - accuracy: 0.8185 - val_loss: 1.2476 - val_accuracy: 0.7738\n",
            "Epoch 8/8\n",
            "12794/12794 [==============================] - 55s 4ms/step - loss: 0.6881 - accuracy: 0.8237 - val_loss: 1.2549 - val_accuracy: 0.7768\n",
            "Validation accuracy: 0.7768152356147766\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Active learning model using bulk\n",
        "def sample_generator(grouped, frac, n_samples):\n",
        "    for label, group in grouped:\n",
        "        # Sort the group by the number of misclassified samples\n",
        "        X_group = group.iloc[:, :-1]\n",
        "        y_group = group.iloc[:, -1]\n",
        "       \n",
        "        if best_model is None:\n",
        "            y_group_pred = np.zeros(len(X_group))\n",
        "        else:\n",
        "            y_group_pred = np.argmax(best_model.predict(X_group), axis=1)\n",
        "       \n",
        "        # Select the most informative misclassified samples for the next iteration\n",
        "        misclassified_indices = (y_group != y_group_pred).values.nonzero()[0]\n",
        "        n_misclassified = len(misclassified_indices)\n",
        "        if n_misclassified == 0:\n",
        "            continue\n",
        "        sorted_indices = np.argsort(-np.bincount(y_group.iloc[misclassified_indices]))\n",
        "       \n",
        "        # Select the top frac fraction of samples from the sorted group\n",
        "        selected_indices = []\n",
        "        n_selected = 0\n",
        "        for i in sorted_indices:\n",
        "            class_indices = (y_group == i).values.nonzero()[0]\n",
        "            n_class_samples = len(class_indices)\n",
        "            n_select = min(int(n_class_samples * frac), n_samples - n_selected)\n",
        "            selected_indices.extend(class_indices[:n_select])\n",
        "            n_selected += n_select\n",
        "            if n_selected >= n_samples:\n",
        "                break\n",
        "       \n",
        "        selected = group.iloc[selected_indices, :]\n",
        "        yield selected\n",
        "   \n",
        "# Define the number of iterations for active learning\n",
        "n_iterations = 3\n",
        "\n",
        "# Define the desired fraction of samples to select from each group\n",
        "frac = 0.003\n",
        "\n",
        "# Initialize the best model and its validation accuracy\n",
        "best_model = None\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    print(f\"Iteration {i+1}/{n_iterations}\")\n",
        "   \n",
        "    # Generate a new golden dataset by selecting informative samples from the bulk dataset\n",
        "    n_samples = len(df_golden) + len(df_golden) * frac\n",
        "    new_golden = pd.concat([df_golden] + list(sample_generator(df_bulk_subset.groupby('target'), frac, n_samples)))\n",
        "   \n",
        "    # Convert the labels to one-hot encoding\n",
        "    X_new = new_golden.iloc[:, :-1]\n",
        "    y_new = new_golden.iloc[:, -1:]\n",
        "    y_new_onehot = ohe.transform(y_new)\n",
        "\n",
        "    # Split the new dataset into training and validation sets\n",
        "    X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(X_new, y_new_onehot, train_size=0.7, shuffle=True)\n",
        "\n",
        "    # Define the model architecture\n",
        "    model_new = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(n_hidden, input_shape=(n_input,), activation='relu'),\n",
        "        tf.keras.layers.Dense(n_class, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model_new.compile(optimizer='adam',\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history_new = model_new.fit(X_train_new, y_train_new, epochs=8, batch_size=8, validation_data=(X_val_new, y_val_new), callbacks=[early_stopping])\n",
        "\n",
        "    # Evaluate the model on the validation set and save it if it has the best accuracy so far\n",
        "    val_acc = history_new.history['val_accuracy'][-1]\n",
        "    print(f\"Validation accuracy: {val_acc}\")\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_new.save('very_active_model')"
      ],
      "metadata": {
        "id": "awfhq3O4Ze4p"
      },
      "id": "awfhq3O4Ze4p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c564de2",
      "metadata": {
        "id": "2c564de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8c5f33-fd37-44ee-bde3-5339fb252ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1301/1301 [==============================] - 2s 1ms/step\n",
            "Accuracy: 0.81\n",
            "Precision: 0.81\n",
            "Recall: 0.81\n",
            "Error rate: 0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#Predict new_model on test golden\n",
        "# Load the golden test set from file\n",
        "test_set = np.load('gold_test_set.npz')\n",
        "X_test_loaded = test_set['X_test']\n",
        "y_test_loaded = test_set['y_test']\n",
        "\n",
        "y_pred_loaded = model_new.predict(X_test_loaded)\n",
        "\n",
        "y_test_loaded = np.argmax(y_test_loaded, axis=1)\n",
        "y_pred_labels = np.argmax(y_pred_loaded, axis=1)\n",
        "\n",
        "y_test = y_test_loaded\n",
        "y_pred = y_pred_labels\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "error_rate = 1 - accuracy\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"Error rate: {error_rate:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the unlabelled golden test feather file\n",
        "df_golden_unlabelled = pd.read_feather('golden_dataset_without_labels.feather')\n",
        "df_golden_unlabelled.head()\n",
        "\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the very active model\n",
        "base_model = load_model('very_active_model')\n",
        "\n",
        "# Make predictions on the unlabelled data using our new very_active_model\n",
        "predictions = base_model.predict(df_golden_unlabelled.iloc[:,:-1])\n",
        "\n",
        "# Add the predicted values as a new column in the dataframe\n",
        "df_golden_unlabelled['target'] = predictions.argmax(axis=-1)\n",
        "\n",
        "df_golden_unlabelled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "88LILD2gdvWc",
        "outputId": "f52c42c0-dbf3-4fab-cf05-75ad70ac0060"
      },
      "id": "88LILD2gdvWc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15484/15484 [==============================] - 20s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0   0.101940  -0.017286   0.084953  -0.951696   0.352282  -0.346768   \n",
              "1   0.231260   0.334692   0.026797  -0.631820   0.270041  -0.149977   \n",
              "2   0.270674   0.118883   0.189267  -0.579700   0.104969   0.061038   \n",
              "3   0.868857   0.153640   0.044309  -0.928379   0.395467  -0.524435   \n",
              "4   0.624732   0.079210   0.098733  -0.876559   0.456947  -0.599581   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_191  feature_192  \\\n",
              "0   0.138993   0.086502   0.714200  -0.146041  ...    -0.447730    -0.532086   \n",
              "1   0.063132   0.375346   0.292597   0.204015  ...    -0.374579    -0.789437   \n",
              "2   0.017830   0.210072   0.375069   0.097011  ...    -0.277504    -0.807677   \n",
              "3   0.404115   0.475237   0.501009  -0.077508  ...    -0.520704    -0.622285   \n",
              "4   0.490737  -0.052870   0.939491   0.025928  ...    -0.453360    -0.640561   \n",
              "\n",
              "   feature_193  feature_194  feature_195  feature_196  feature_197  \\\n",
              "0    -0.224644    -0.228299     0.090918     0.183534    -0.132292   \n",
              "1    -0.012622    -0.099412    -0.150186    -0.102274    -0.073857   \n",
              "2     0.120687    -0.258360    -0.112257    -0.071628    -0.092532   \n",
              "3    -0.547424    -0.231111     0.151586     0.130592     0.081846   \n",
              "4    -0.455199    -0.552339    -0.157240     0.103550    -0.402685   \n",
              "\n",
              "   feature_198  feature_199  target  \n",
              "0    -0.090970    -0.503340     401  \n",
              "1     0.199650    -0.118662     366  \n",
              "2     0.173010    -0.166538     366  \n",
              "3     0.153175    -0.599044     374  \n",
              "4     0.146011    -0.118169     392  \n",
              "\n",
              "[5 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e72a00c1-359a-4160-91da-b4def8d2c3f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_191</th>\n",
              "      <th>feature_192</th>\n",
              "      <th>feature_193</th>\n",
              "      <th>feature_194</th>\n",
              "      <th>feature_195</th>\n",
              "      <th>feature_196</th>\n",
              "      <th>feature_197</th>\n",
              "      <th>feature_198</th>\n",
              "      <th>feature_199</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.101940</td>\n",
              "      <td>-0.017286</td>\n",
              "      <td>0.084953</td>\n",
              "      <td>-0.951696</td>\n",
              "      <td>0.352282</td>\n",
              "      <td>-0.346768</td>\n",
              "      <td>0.138993</td>\n",
              "      <td>0.086502</td>\n",
              "      <td>0.714200</td>\n",
              "      <td>-0.146041</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.447730</td>\n",
              "      <td>-0.532086</td>\n",
              "      <td>-0.224644</td>\n",
              "      <td>-0.228299</td>\n",
              "      <td>0.090918</td>\n",
              "      <td>0.183534</td>\n",
              "      <td>-0.132292</td>\n",
              "      <td>-0.090970</td>\n",
              "      <td>-0.503340</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.231260</td>\n",
              "      <td>0.334692</td>\n",
              "      <td>0.026797</td>\n",
              "      <td>-0.631820</td>\n",
              "      <td>0.270041</td>\n",
              "      <td>-0.149977</td>\n",
              "      <td>0.063132</td>\n",
              "      <td>0.375346</td>\n",
              "      <td>0.292597</td>\n",
              "      <td>0.204015</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>-0.789437</td>\n",
              "      <td>-0.012622</td>\n",
              "      <td>-0.099412</td>\n",
              "      <td>-0.150186</td>\n",
              "      <td>-0.102274</td>\n",
              "      <td>-0.073857</td>\n",
              "      <td>0.199650</td>\n",
              "      <td>-0.118662</td>\n",
              "      <td>366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.270674</td>\n",
              "      <td>0.118883</td>\n",
              "      <td>0.189267</td>\n",
              "      <td>-0.579700</td>\n",
              "      <td>0.104969</td>\n",
              "      <td>0.061038</td>\n",
              "      <td>0.017830</td>\n",
              "      <td>0.210072</td>\n",
              "      <td>0.375069</td>\n",
              "      <td>0.097011</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.277504</td>\n",
              "      <td>-0.807677</td>\n",
              "      <td>0.120687</td>\n",
              "      <td>-0.258360</td>\n",
              "      <td>-0.112257</td>\n",
              "      <td>-0.071628</td>\n",
              "      <td>-0.092532</td>\n",
              "      <td>0.173010</td>\n",
              "      <td>-0.166538</td>\n",
              "      <td>366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.868857</td>\n",
              "      <td>0.153640</td>\n",
              "      <td>0.044309</td>\n",
              "      <td>-0.928379</td>\n",
              "      <td>0.395467</td>\n",
              "      <td>-0.524435</td>\n",
              "      <td>0.404115</td>\n",
              "      <td>0.475237</td>\n",
              "      <td>0.501009</td>\n",
              "      <td>-0.077508</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.520704</td>\n",
              "      <td>-0.622285</td>\n",
              "      <td>-0.547424</td>\n",
              "      <td>-0.231111</td>\n",
              "      <td>0.151586</td>\n",
              "      <td>0.130592</td>\n",
              "      <td>0.081846</td>\n",
              "      <td>0.153175</td>\n",
              "      <td>-0.599044</td>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.624732</td>\n",
              "      <td>0.079210</td>\n",
              "      <td>0.098733</td>\n",
              "      <td>-0.876559</td>\n",
              "      <td>0.456947</td>\n",
              "      <td>-0.599581</td>\n",
              "      <td>0.490737</td>\n",
              "      <td>-0.052870</td>\n",
              "      <td>0.939491</td>\n",
              "      <td>0.025928</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.453360</td>\n",
              "      <td>-0.640561</td>\n",
              "      <td>-0.455199</td>\n",
              "      <td>-0.552339</td>\n",
              "      <td>-0.157240</td>\n",
              "      <td>0.103550</td>\n",
              "      <td>-0.402685</td>\n",
              "      <td>0.146011</td>\n",
              "      <td>-0.118169</td>\n",
              "      <td>392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e72a00c1-359a-4160-91da-b4def8d2c3f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e72a00c1-359a-4160-91da-b4def8d2c3f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e72a00c1-359a-4160-91da-b4def8d2c3f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataframe to a numpy array\n",
        "import numpy as np\n",
        "data = df_golden_unlabelled.values\n",
        "\n",
        "# Save the numpy array as a .npy file\n",
        "np.save('Group13_Prediction_2.npy', data)"
      ],
      "metadata": {
        "id": "FSaOorI4dxqO"
      },
      "id": "FSaOorI4dxqO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}